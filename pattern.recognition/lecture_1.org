#+TITLE:        Распознавание образов
#+AUTHOR:       Дмитрий Кравцов
#+EMAIL:        idkravitz@gmail.com
#+DATE:         11 февраля 2011 года.
#+DESCRIPTION:  набор лекций по (см. тайтл) 
#+LANGUAGE:     russian
#+LATEX_HEADER: \usepackage[russian]{babel} \usepackage[T2A]{fontenc} \usepackage[utf8]{inputenc}
#+TAGS: PatternRecognition

* Введение в распознавание образов

Распознавание образов -- отнесение наблюдаемого объекта (процесса,
явления) к одному из нескольких классов. Способность к распознаванию
образов это одно из свойств человека и живых существ. В целом говоря о
проблеме распознавания образов имеют ввиду 2 класса задач:

1. Изучение способности человека к распознаванию.
2. Развитие теории и методов построения устройств предназначенных для
   решения задач распознавания.

Распознавание образов -- наука, занимающаяся проблемой создания и
технических и программных устройств распознавания

** История

1. История (началось с 20 века) -- теория статистических решений.
2. 1950г. -- теория искусственных нейронных сетей. Именно тогда в рамках тех задач и родилось название
   класса задач -- распознавание образов.
3. С 1980г. возникли серьёзные продвижения в нейросетевой парадигме, появления множество методов и
   статей, описывающих эти методы.

** Решаемые задачи

Задача распознавания образов может активно перетекать в задачу распознавания сцен (изображения лиц,
собраний, людей\ldots). Сложные решения обычно базируются на простых
решениях.\\
#+LABEL pic1:simple_pr
#+CAPTION: простой решатель
#+ATTR_LaTeX: width=480px
[[./images/pic1.png]]

По приведённой схеме работают простые системы распознавания образов. Например задача распознавания
текста может и не быть простой, если модель решения задачи усложнена (выделение области текста, выпил слов
и т.д.). Для описания объекта достаточно лишь определить к какому классу он относится.

*** Пример 1
Объект: кристалл соли (NaCl). Описание объекта -- положения атомов в кристаллической решётке и прочие 
параметры, поэтому решить на ЭВМ не представляется возможным. Поэтому задача ставится например так:
1. Соль это или сахар.
2. Если соль, то мелкого или крупного помола.


*** Пример 2
Объект: Человек.\\
Задача распознавания 1: ребёнок это или взрослый.\\
Задача распознавания 2: спокойный это человек или возбуждённый.\\
Задача распознавания 3: Вася или Петя.

Датчик (или рецептор) осуществляет первичное восприятие образов. Для разных задач распознавания могут
применяться разные датчики. Если речь идёт о человеке то его рецепторы: глаза, уши, пальцы\ldots Если это
техническая система -- видеокамера, цифровой фотоаппарат\ldots

** Информационные структуры, которые могут восприниматься датчиками

Первичные данные - данные, воспринимаемые датчиками.

- некий числовой параметр (температура человека).
- группа параметров (температура тела, пульс, давление).
- случайный сигнал (ЭЭГ (электроэнцефалограмма) -- замер разности потенциалов между точками головы 
  во времени).
- система случайных сигналов (ЭКГ (большое количество точек измерения) -- то же что и выше но больше
  точек замера).
- изображение ($f(x,y)$ -- непрерывный случай и $\{f_{ji}\}, j=1,\ldots, n, i=1,\ldots, k$).
- система изображений (многозональные спутниковые снимки).
- видео ($f(x,y,t)$).
  
* Прикладная теория вероятности

*Теория вероятности* -- математическая наука, изучающая закономерности в
случайных явлениях. *Случайное явление* -- явление, которое при
неоднократном воспроизведении одного и того же опыта всякий раз
протекает несколько по разному.

Насколько распространены случайные явления? Они присутствуют
повсеместно. Пример: стрельба из пушки по цели. Как попасть в цель?
Нужно составить некоторую модель полёта, воспользовавшись методами из
механики. При просчёте по простейшей модели реальный снаряд упадёт
раньше (ближе) чем рассчитано, тогда можно ввести в расчёт учёт
сопротивления воздуха (форма, баллистический коэффициент). Тогда
траектория станет ещё более точной, но мы всё равно получим набор
недетерминированных траекторий. Словом почти всегда есть элемент
случайности, который не удаётся устранить. 

1. *Случайные события* -- всякий факт, который в результате опыта может
   произойти или не произойти. $A \to P(A)$

2. *Случайная величина* -- величина, принимающая в результате опыта
   значение, заранее неизвестно какое. Сабж бывает дискретным
   (область конечна или счётна) и непрерывным. Полное описание
   случайной величины -- закон распределения вероятности, который
   указывает какие возможные значения более возможны и какие
   менее. Для случайной величины есть универсальный вид *закона
   распределения* -- функция распределения $F(x)$. Кроме того для
   дискретных случайных величин распространена форма задания закона
   распределения в виде ряда распределения (таблица вероятностей). Для
   непрерывной случайной величины используют часто $f(x)$ -- *плотность
   распределения*.

3. Опыты, результаты которых фиксируются в виде *набора (системы)
   случайных величин* ($\bar x = (x_1,\ldots,x_n)$).
   Примеры важных численных характеристик: среднее значение случайной
   величины $\bar x$, дисперсия $D(\bar x)$, корреляционные величины.
   Полное описание -- закон распределения $f(\bar x)$ или $F(\bar
   x)$. Числовые характеристики представляют собой неполное описание.

4. Случайные функции ($X(t)$) (..переписать..)

** Случайные события

*Достоверное событие* -- событие, которое обязательно происходит во
всяком опыте ($U, \Omega$). Событие $V, \varnothing$ -- *невозможное*
событие. Если есть событие $A$, то $\bar A$ -- *дополнительное* к $A$
событие. Очень часто пользуются графической иллюстрацией на
плоскости. События $A$ и $B$ *несовместны*, если они не могут произойти
одновременно. $\{A_1,\ldots,A_n\}$ -- группа событий, является
несовместной, если любая пара различных событий из неё являются
несовместной. Очевидное свойство -- $A$ и $\bar A$ несовместны. Полная
группа событий $\{A_1,\ldots,A_n\}$, если в результате всякого опыта
произойдёт хотя бы одно из событий группы. Полная группа несовместных
событий -- полная, несовместная группа.
*** Отношения между событиями
+ *Включение*: $A \subset B$. $A$ происходит всякий раз, когда
   происходит $B$
+ *Отношение эквивалентности*: $A = B$, если $A \subset B$ и $B
   \subset A$.
*** Операции над событиями
+ *Сумма*: $C=A+B$, $C$ происходит тогда и только тогда, когда
  происходит либо $A$ либо $B$

+ *Умножение*: $C = AB$ происходит тогда и только тогда, когда
  происходит и $A$ и $B$
+ *Разность*: $C = A - B = A\bar B$

$A$ и $B$ несовместны, если $AB = \varnothing$.
$\{A_i\}$ -- полная группа, если $\sum A_i = \Omega$.
$\{A_i\}$ -- полная группа несовместных событий, если `

События могут быть составными и элементарными. Составные могут быть
представлены через другие события. Элементарные являются
неразложимыми (обозначаются например \omega). Когда рассматривают или
расписывают математически некоторый случайный опыт всегда первым делом
описывают пространство элементарных событий (ПЭС) -- полная группа
несовместных элементарных событий. Достоверное событие \Omega состоит
из всех событий из ПЭС. Различают дискретные и непрерывные ПЭС.
Дискретное:
1. Конечное число исходов. \Omega =
   \{\omega_1,\omega_2,\ldots,\omega_n\}
2. Счётное число исходов. $\Omega = \{\omega_1,\omega_2,\ldots\}$
   (например бросание кости до первой 6)

Непрерывное ПЭС:
Множество элементарных исходов не счётно. Например стрельба по мишени,
когда результат -- пара координат, куда попала пуля,
т.е. $\omega=(x,y), \Omega=\{\omega:-\infty<x,y<\infty\}$

Далее необходимо определить алгебру событий (пространство
событий). Множество событий U, составленное из ПЭС, которое может
интересовать нас с точки зрения расчёта вероятности этих событий. В U
обязательно должно быть:
1. Нулевой и единичный элементы $(\varnothing, \Omega)$.
2. Для $\forall A \in U \exists \bar A \in U$
3. Для $\forall \{A_i \in U\}_{i=\overline{1,\infty}} \sum A_i \in U, \prod
   A_i \in U$
Измеримые подмножества из ПЭС составляют Барелевскую алгебру.
Два крайних случая множества U:
1. U = $\{\varnothing,\Omega\}$
2. U = все возможные подмножества ПЭС
Двойка $\{\Omega, U\}$ -- измеримое пространство. $\forall A \in U,
P(A)$ - вероятность события A. 

Вероятностью P называют числовую функцию, определённую на элементах
\sigma-алгебре событий, удовлетворяющую следующим аксиомам:
1. $P(A) \geqslant 0, \forall A \in U$
2. $P(\Omega)=1$
3. $P(\sum_{i=1}^n A_i)=\sum_{i=1}^n P(A_i)$, если \{A_i\} --
   несовместны.
4. $P(\sum_{u=1}^\infty A_i) = \sum_{i=1}^\infty P(A_i)$, если \{A_i\}
   -- несовместны.
   
** Вероятностое пространство

Тройка (\Omega, U, P(A)), тут \Omega - ПЭС. Основная цель -- отыскание
P(A).
Частота и статистическая вероятность. Пусть A и B -- совместны и
оказалось, что число осуществления A >> числа осуществления B. Тогда у
нас большие основания полагать, что P(A) > P(B).

Пусть A -- некоторое событие. $\nu_n(A) = \frac{\nu(A)}{n}$ -- частота
события А. $\nu(\varnothing)=0,\nu(\Omega)=1$, $\nu_n(A)\geqslant 0$,
$\nu_n(A+B)=\nu_n(A) + \nu_n(B) - \nu_n(A\cap B)$. Проведём 2 раза по
n опытов: $\nu_A'\neq\nu_A?$. При $n\to\infty \Rightarrow |\nu_A' - nu_A| \to
0$ предельное значение $\nu_A = P(A)$.

Факт стремления $\nu_n(A)\to P(A)$ был установлен Якобом Бернули, и
этот факт стал известен как Закон Больших Чисел $$\lim_{n\to\infty}
\nu_n(A)=P(A)$$

Вероятностная сходимость отличается от обычной. Для $\forall
\varepsilon > 0$ справедливо
$\lim_{n\to\infty}P(|\nu_n(A)-P(A)|<\varepsilon)=1$. Статистическая
вероятность:
$\hat P(A) = \nu_n(A) = \frac{n(A)}{n}$

$\Delta P(A)=|\nu_n(A) - P(A)|$, $\frac{\Delta P(A)}{P(A)}$ -- относительная ошибка, при этом $\Delta
P(A) \sim P(A)\frac{1}{\sqrt{n}}$. 

* Классическая вероятность
Вероятность события A определяется отношением числа исходов,
благоприятных событию A к общему числу *равновозможных* исходов опыта. 
$$
P(A)=\frac{n(A)}{n}
$$

Спроецируем классические вероятности на аксиоматическое определение
вероятности
1. ПЭС - конечное, $\Omega=(\omega_1,\ldots,\omega_n)$.
2. $U$ - обычная алгера, включающая все комбинации элементарных
   исходов ($|U|=2^n$)
3. $P(\omega_k)=\frac{1}{n},\forall k=\overline{1,n}$. $\forall A\in
   U$ соответствует некоторая совокупность элементарных исходов
   (например $\omega_3,\omega_7,\omega_{11}$). Тогда по 3-ей аксиоме
   вероятности $P(A)=\sum_{\omega_i\in A} P(\omega_i)=
   \sum_{n(A)}\frac{1}{n}=\frac{n(A)}{n}$

Пример есть 5 шаров (3 белых, 2 чёрных). Элементарное событие --
вытащили шар. $P(A)=\frac{3}{5}$, $P(B)=\frac{2}{5}$. Если вытащили 2
шара $P(A)=\frac{C^2_3}{C^2_5}=\frac{3!3!2!}{2!5!}=0.3$

Предположим, что реализована схема с возвращением шаром, тогда, если A
-- оба белые: $P(A)=\frac{3^2}{5^2}=\frac{9}{25}=0.36$

** Комбинаторные схемы
1. Выбор r элементов из групп с числами элементов
   $n_1,n_2,\ldots,n_r$. $N=n_1\cdot n_2\cdot\ldots\cdot n_r$
2. Выбор r элементов из одной группы с возвращением (эквивалентно r
   групп по n элементов), $N=n^r$. Эта задача эквивалентна размещению
   r элементов по n ящикам
3. Выбор r элементов из  n элементов по схеме без возвращения \equiv
   размещение r элементов по n ящикам, но не более одного элемента в
   ящик. $N=n(n-1)\cdot\ldots\cdot (n-r+1)=\frac{n!}{(n-r)!}=A^r_n$ --
   число размещений из n по r. Перестановка: $N=n!$
4. Выбор r неразличимых элементов из n элементов
   $N = \frac{A^r_n}{r!} = \frac{n!}{(n-r)!r!} = C^r_n$

** Геометрическая вероятность
Возникает когда выбор наудачу точки из некоторой области $\Omega$ в
некотором пространстве $R$. Событие A происходит если $A\in
\Omega$. Объём $A = \mu(A)$, $\Omega = \mu(\Omega)$, $P(A) =
\frac{\mu(A)}{\mu(\Omega)}$. Если работаем с $R^1$, то объём -- длина
отрезка. $R^2$ -- площадь.

1. ПЭС -- множество точек $R^n\subset \Omega$.
2. U -- множество всех подобластей, лежащих в $\Omega$ и имеющих
   ненулевой объём.
3.  $P(A) \sim \mu(A)$ \\
   $P(\Omega)=1 \sim \mu(\Omega)$

Пример: 2 человека договорились встретиться между $13^{00}$ и
$14^{00}$ обязательно каждый из них придёт в этом
интервале. Договорились, что ждут друг друга не более 10 минут.

$\Omega=\{(\xi,\eta): 0\leqslant \xi, \eta \leqslant 60\}$,\\
$\mu(\Omega)=60^2$, $A=\{(\xi, \eta): |\xi - \eta| \leqslant
10\}$. Рисуночек, $\mu(A)=60^2 - 50^2$, $P(A) = 1 -
\frac{50^2}{60^2}=\frac{11}{36}$

** Косвенные методы нахождения вероятностей
A -- сложное событие. P(A)=?
B,C,D -- более простые события, вероятности их могут быть легко
найдены. Тогда мы можем предположить, что событие A можно с помощью
правил алгебры событий представить через события B, C, D (A=F(B,C,D))
-- в этой конструкции будут 2 базовые операции: сложение и умножение
событий. Если мы будем знать как находить $P(B+C)$ -- теорема сложения
вероятностей, $P(BC)$ -- теорема умножения вероятностей.

*** Теорема сложения
P(A+B)=P(A)+P(B)-P(AB)

*** Теорема умножения
Введём понятие условной вероятности: P(A/B) -- условная вероятность
события A, при условии, что событие B уже произошло. Если
$P(A/B)=P(A)$, то A не зависит от B. Если $P(A/B)=P(A)$, то
$P(B/A)=P(B)$.

P(AB) = P(A) P(B/A)=P(B) P(A/B)
$P(A_1,\ldots, A_n) = P(A_1)P(A_2/A_1)P(A_3/A_1A_2)\ldots
P(A_n/A_1\ldots A_{n-1}$

Для независимых:
$P(AB) = P(A)P(B)$
$P(\prod A_i)=\prod_{i=1}^n P(A_i)$

*Пример:*\\
w - white, b - black.
 $P(ww) = P(1w)P(2w/1w) = \frac{3}{5}\cdot\frac{2}{4} = 0.3$ \\
*Если случай с возвращением:* $P(ww)=P(1w)P(2w) = \frac{9}{25}$

* Два важных следствия из теорем сложения и произведения

** Формула полных вероятностей

Пусть $H_1,\ldots,H_n$ -- полная группа несовместных событий
(гипотез). Пусть событие $A$ -- событие, которое происходит совместно
с одной из гипотез. Тогда имеем замечательную формулу:

$$
    P(A) = \sum_{k=1}^n P(H_k)P(A)
$$

*Вывод формулы*: $A=AH_1 + AH_2 + \ldots + AH_n$ (все события в сумме
являются несовместными).

Пример. Имеются 3 урны, в первой: 2 белых + 1 чёрный, во второй: 3
белых и 1 чёрный, в третей: 2 белых и 2 чёрных. Найти $P(A)$ --
вытащили белый мячик, 
гипотезы $H_i$ -- вытащили из i-й урны,
$P(H_1)=P(H_2)=P(H_3)$. $P(A/H_1) = \frac{2}{3}$,
$P(A/H_2)=\frac{3}{4}$, $P(A/H_3) = \frac{1}{2}$. Ну а далее применяем
формулу полных вероятностей.

** Формула Байесса. Теорема гипотез
Итак имеется полная группа гипотез $H_1,\ldots,H_n$. Известны $P(H_k)$
-- априорные вероятности гипотез. Имея возможность провести опыт $A$
мы можем скорректировать вероятности. Итак порой очень часто важно иметь
апостериорные вероятности
$P(H_k/A)=\frac{P(H_k)P(A/H_k)}{P(A)}$. Пример тот же с тремя урнами.

* Случайные величины
*Случайная величина* -- это величина, которая в результате опыта
приобретает определённое числовое значение, заранее неизвестное. Это
определение для домохозяек, а математическое это:

Пусть тройка $(\Omega, U, P)$ -- некоторое вероятностное
пространство, *случайной величиной* $\xi$ называют действительную
функцию $\xi=\xi(\omega)$, где $\omega \in \Omega$, такую, что при
\forall действительных X $\{\omega: \xi(\omega)<X\}\subset U$.

Область возможных значений случайной величины X может быть дискретной
либо непрерывной, соответственно их разделяют на 2 класса: а)
дискретные случайные величины и б) непрерывные случайные величины. Как
задать описание случайной величины? Наиболее полное описание случайной
величины -- это закон распределения случайной величины (всякое
соотношение, указывающее связь между возможными значениями случайной
величины и их вероятностями. 

*Дискретные случайные величины*. Для них применяется ряд вероятностей
 случайной величины

| X | X_1 | X_2 | \ldots | X_n |
|---+-----+-----+--------+-----|
| P | P_1 | P_2 | \ldots | P_n |

При этом $\sum P_n = 1$

Ещё можно задавать многоугольником.

Функция распределения. $F(x) = P(X < x)$, $x \in (-\infty,+\infty)$
Свойства:
1. $F(x)$ -- неубывающая
2. $\lim_{x\to-\infty}F(x)=0$, т.к. $P(\varnothing)=0$
3. $\lim_{x\to+\infty}F(x)=1$, т.к. $P(\Omega)=1$
4. $P(a < x \leqslant b) = F(b) - F(a)$

Для дискретной случайной
величины. $F(x)=P(X<x)=\sum_{x_k<x}P(X=x_k)$. При всём этом $F(x)$ --
ступенчатая. Зная функцию распределения можно построить ряд
распределения.

Теперь об особенностях $F(x)$ для непрерывной случайной
величины. $F(x)$ -- непрерывна, монотонна.

Плотность распределения непрерывной случайной величины. Пусть $x$ --
непрерывная случайная величина. $P(X=x) \equiv 0$, поэтому таблица
невозможна. $P(x \leqslant X < x + \delta x)$. Нормируем это счастье
$\frac{P(x\leqslant X < x + \delta x)}{\delta x} = \frac{F(x+\delta
x) - F(x)}{\delta x}$. Тогда в предельном переходе
$f(x)=\frac{dF(x)}{d(x)}$. Теперь восстановим функцию распределения:

$$
    F(x) = \int^x_{-\infty}f(\xi)d\xi
$$

Свойства:
1. $f(x)\geqslant 0$
2. $\int^{+\infty}_{-\infty}f(x) dx = 1$
3. $P(a<x<b)=\int^b_a f(x) dx$

Резюме. Для дискретных случайных величин: ряд распределения и функция
распределения. Для непрерывных случайных величин: функция
распределения и плотность распределения.

Дополнение. Иногда возникает соблазн использовать и там и там
плотность распределения. Распространим плотность на дискретные
случайные величины, для этого используются так называемая $\delta(x)$

\begin{equation}
\delta(x) = \left\{\begin{aligned}
            &\infty, &x=0, \\
            & 0,     &x \neq 0
            \end{aligned}\right.
\end{equation}

На неё наложено следующее ограничение:
$\int^{+\infty}{-\infty}\delta(x)dx = 1$.

Дельта функция обладает важным фильтрующим свойством.
$g(y)=\int^{+\infty}{-\infty} g(x) \delta (y - x) dx$ --
свёртка. Используется для выделения значения функции $g$.

Пусть X -- дискретная случайная величина, заданная таблицей
вероятностей. Вводим функцию плотности 
$$
f(x) = \sum^n_{k=1} P_k \delta(x - x_k)
$$

* Числовые характеристики случайной величины
Это неполное знание о случайной величине, но оно может быть
достаточным для каких-то целей 
1. Мода случайной величины -- наибольшее возможное значение случайной
   величины. Если много пиков у плотностей распределения, то говорят,
   что закон распределения полимодальный (много мод)
2. Квантиль распределения порядка $p$ -- $x_p$. Он определяется из
   условия $F(x_p) = P(X < x_p) = p$. Их ввели, когда надо было
   работать с плотностями распределений, заданных на
   бесконечности. Квантили малых и больших порядков применяются для
   ограничения области возможных значений случайных величин. Например
   самые малые $x_{0.001},x_{0.999}$, самые частые
   $x_{0.05},x_{0.95}$. Основное назначение квантилей -- задать
   область интересующих нас значений.
3. Медиана. $\mu_e = x_{0.5}$, задаёт среднюю точку распределения.

* Характеристики, основанные на моментах распределения случайной величины
Математическое ожидание $M[X] = \sum_{i=1}^{n} x_i R_i =
\int_{-\infty}^{\infty} x f(x) dx$
Пусть мы провели серию из $N$ опытов $x^{(1)}, x^{(2)}, \ldots, x^{(n)}$.
Построим среднее арифметическое $\hat {\bar x} = \frac{1}{N} \sum_{i=1}^{N}
x^{(i)}$ (случайная величина). Если $M$ возрастает, то $x$
стабилизируется у некоторого числового значения. В предельном переходе
$\lim_{N \to \infty} \frac{1}{N} \sum x_i = M[X]$ (закон больших
чисел, вторая формулировка). 
# добавить крышечку к $\hat\bar x$
Пусть $X$ -- случайная величина и $\varphi (X)$ некоторая функция от
$X$.
$M\left[\varphi \left(X\right) \right] =$
$\sum_{i=1}^{n} \varphi (x_i) p_i =$
$\int_{-\infty}^{\infty} \varphi (x) f(x) dx$
Начальные моменты:
$m_k = M[X^k] = \sum_{i=1}^{n} x_{i}^{k} p_i = \int_{-\infty}^{\infty}
x^k f(x) dx$ - (начальные моменты к-ого порядка), $k = 0, 1, 2, 3, \ldots$
$\mu_k = M[(x-\bar x)^k]=\sum (x_i - \bar x)p_i = \int (x-\bar
x)f(x) dx$ -- центральные моменты, $k = 0,1,2,\ldots$
$m_k$ и $\mu_k$ связаны:
1. $\mu_1 = 0$
2. $\mu_2 = m_2 - m_1^2$
3. $\mu_3 = m_3 - 3m_1m_2 + 2m_1^3$

Можно показать, что зная все моменты $m_k, \mu_k$, $k=0,\ldots$ можно
точно восстановить закон распределения. 

** COMMENT Числовые характеристики, основанные на первых четырёх моментах.
1. Мат.ожидание случайной величины (среднее случайной величины): $$\bar
   x = M[x]=m_1=\sum x_ip_i = \int\limits^{+\infty}_{-\infty} xf(x)dx$$. Эта характеристика
   "положения" закона распределения, указывает около какого значения
   разыгрываются значения случайной величины. 
2. Дисперсия: $$ D_x = \varsigma^2_x = \mu_2 = M[(x-\bar x)^2]$$
   Также введём среднеквадратичное отклонение: $$ \varsigma_x =
   \sqrt{D_x} $$
3. Коэффициент вариации (волны на море -- представим волны на море,
   развился какой-то волновой процесс (в разрезе, продольные волны),
   разброс:
    $$ r_x=\frac{\varsigma_x}{\bar x} $$
4. Коэффициент асимметрии. Пример:
   \begin{gather*}
   \bar x_1 = \bar x_2 = \bar x_3 \\
   \varsigma_1^2 = \varsigma_2^2 = \varsigma_3^2
   \end{gather*}
   $$ \gamma = \frac{\mu_3}{\varsigma^3} = \frac{M[(x-\bar
   x)^3]}{\varsigma^3}$$
   1. $\gamma = 0$ кубы чототам компенсируют, симметричные законы.
   2. $\gamma > 0$ для несимметричных законов, скошенных вправо.
   3. $\gamma < 0$ для несимметричных законов, скошенных влево.
 
5. Коэффициент эксцесса (характеристика
   плосковершинности/островершинности законов распределения)
   $$ \kappa = \frac{\mu_4}{\sigma^4} - 3 $$

* Некоторые важные законы распределения
** Равномерное распределение
Пусть $X$ --- непрерывная случайная величина, заданная на отрезке
$[\alpha, \beta]$, все значения равновозможны.
$$f(x) = \frac{1}{\beta-\alpha}, x \in [\alpha, \beta]$$
$$f(x) = 0, x \not \in [\alpha, \beta]$$
$$F(x) = 0, x < \alpha$$
$$F(x) = \frac{x-\alpha}{\beta-\alpha}, x \in [\alpha, \beta]$$
$$F(x) = 1, x > \beta$$
** ?
1. Моды нет
2. Медиана
   $$\mu_l = \frac{\alpha+\beta}{2}$$
3. Математическое ожидание
   $$\bar x = \frac{\alpha+\beta}{2}$$
4. Дисперсия
   $$D = \frac{(\beta - \alpha)^2}{12}$$
5. Среднеквадратичное отклонение
   $$\varsigma = \frac{\beta - \alpha}{2\sqrt{3}}$$
6. ??
   $$\gamma = 0$$
7. ??
   $$\kappa = -1.2$$

** Распределение Бернулли
Схема Бернулли:
Пусть событие A происходит с вероятностью P, проводится n опытов. При
этом k -- количество опытов в которых событие A произошло. Бернулли
поставил вопрос о том какова вероятность $P_n(k)$. Он же и получил
формулу:
 $$
 P_n(k) = C^k_nP^k(1-p)^{n-k}
 $$
Иногда его ещё называют биномиальное распределение (поскольку являются
биномами Ньютона). Доказательство:

Предположим, что в серии из $n$ опытов мы получили
конфигурацию 01001001. Нас интересует $P(01001001)$ =
p^k(1-p)^{n-k}. Одинаковые k буду иметь все перестановки данной
конфигурации, а их $C_n^k$. Получаем интересующую нас формулу.

1. Мода $\mu=[(n+1)p]$ ($[]$ -- целая часть (округление влево)),
2. $\bar x = np$
3. $\varsigma_x^2 = npq = np(1-p)$

Из распределения Бернулли асимптотически вытекают два важных
распределения

** Распределение Пуассона
Асимптотика распределения Бернулли. При $n\to \infty$, но
рассматриваются такие случаи, что при этом $p\to 0$, и ещё при этом
$np=a$ -- константа. Случайная величина $k$ будет дискретной со
счётным числом возможных значений (бесконечное число возможных
значений).
 $$
 P(k) = \frac{a^k}{k!}e^{-a}
 $$
Числовые характеристики:
1. $\bar k = a$
2. $\varsigma^k_k = a$

** Нормальное распределение (Гауссово)
Асимптотика Бернулли следующего вида. $n\to \infty$, p --
константа. Введем случайную величину $x_k = \frac{k-np}{\sqrt{npq}}$,
если перейти к непрерывному случаю, то 
 $$
 f(x) = \frac{1}{\sqrt{2\pi}}e^{\frac{-x^2}{2}}
 $$
Числовые характеристики:
1. $\bar x = 0$
2. $\varsigma_x^2 = 1$

 $$
 F(x) = \frac{1}{\sqrt{2\pi}}\int^{x}_{-\infty}e^{-x^2}{2}dx = \Phi(x)
 $$

Тут $\Phi(x)$ -- интеграл вероятности, не имеет аналитического
значения.

Итак теперь о ненормированных, а просто нормальных случайных
величин. Говорят что случайная величина $X \sim N(a, \varsigma^2)$,
 $$
  f(x) =
  \frac{1}{\sqrt{2\pi}\varsigma}e^{-\frac{(x-a)^2}{2\varsigma^2}}
 $$
 $$
  F(x) = \Phi(\frac{x-a}{\varsigma})
 $$

Числовые характеристики:
1. $\mu=a$
2. Медиана $\mu_e=a$
3. $\bar x = a$
4. $D[x] = M[(x-a)^2] = \varsigma^2$
5. $\gamma = 0$
6. $\kappa = 0$
Почему нормальный закон такой важной в теории вероятности и
мат. статистике?

1. Пусть X -- случайная величина (с плотностью f(x)). $Y=X_1 + X_2$, при этом закон
   распределения Y будет отличаться от $f(x)$, что не удобно. Если X \sim
   N(a, \varsigma^2), то Y -- останется нормальным

2. Пусть X -- случайная величина (с плотностью f(x)). $Y =
   \sum_{i=1}^n x_i$, пусть n растёт, тогда неважно каким был закон
   распределения $f(x)$, закон распределения Y будет стремиться к
   нормальному распределению. Этот результат получил название ЦПТ
   (Центральная Предельная Теорема)

3. Для полного описания любого закона распределения нужно знать все
   его начальные и центральные моменты, $m_k, \mu_k$ для $k=1,\ldots
   \infty$. В то же время для нормального закона достаточно знать $m_1
   = a$, $\mu_2 = \varsigma^2$. $\mu_k = (k-1)!!\varsigma^k$ -- случай
   k - чётное и $\mu_k = 0$, при k - нечётном.

** Расчёт вероятности попадания в произвольный интервал
$P(\alpha < x < \beta) = F(\beta) - F(\alpha) =
\Phi(\frac{\beta - a}{\varsigma^2}) - \Phi(\frac{\alpha -
a}{\varsigma^2})$. А если $X ~ N(a, \varsigma^2)$, то $P(a-\varsigma <
x < a + \varsigma) \approx 0.65 \approx \frac{2}{3}$, ещё интересна
такая штука $P(a - 2\varsigma < x < a + 2\varsigma) \approx 0.96$,
$P(a - 3\varsigma < x < a + 3\varsigma) \approx 0.997 \approx 1$
(т.е. почти все вероятности лежат в последнем интервале). В
различной литературе рекомендуют применять правило "трёх \varsigma",
для устранения артефактов в сигнале.

* Оценивание числовых характеристик на основе опытных данных
$\hat P(A) = \frac{N(A)}{N}$ (статистическая вероятность).
Пусть $X$ --- случайная величина с некоторыми законами распределения
и некоторыми числовыми характеристиками. В нашем распоряжении
находится совокупность характеристик $(x_1, x_2, \ldots x_n)$.

** Точечное оценивание
$\hat \theta_n$ должна обладать "хорошими" свойствами:
1. Несмещённость: $M[\hat \theta_n] = \theta$
2. Состоятельность: $\lim_{n \to \infty} \hat \theta_n = \theta$
3. Эффективность: минимальная дисперсия $\forall n$, то есть
$$min D[\hat \theta_n] = M[(\hat \theta n - \theta)^2]$$

** Интервальное оценивание
Задаёмся некоторым уровнем доверия $\gamma = 0.95, 0.99, 0.999$.
Результат оценивания --- диапазон $[\theta_1, theta_2]$ такой, что
$$P[\theta_1 < \theta < \theta_2] \geqslant \gamma$$.

Вернёмся к задаче.
$$\hat m_k = \frac{1}{n} \sum_{i=1}^n x_i^k$$
Отметим, что $\hat {\bar x} = \frac{1}{n} \sum x_i$.
$$\hat \mu_k = \frac{1}{n} \sum (x_i - \hat {\bar x})^k$$

** Формулы для второй л/р
1. $\hat {\bar x} = \frac{1}{n} \sum x_i$
2. $\hat D = \hat \varsigma^2 = \frac{1}{n} \sum (x_i - \hat {\bar
   x_i})^2$
3. $\hat \gamma = \frac{\frac{1}{n} \sum (x_i \hat {\bar x_i})^3}{\hat
   \varsigma^3}$
4. $\hat \kappa = \frac{\frac{1}{n} \sum (x_i - \hat {\bar
   x_i})^4}{\hat \varsigma^4}$

** Оценивание законов распределения
*** Статистическая функция распределения
$$\hat E(x) = \hat P(X < x) = \frac{n(X < x)}{n}$$
Как строят оценки таких функций?
Пусть $(x_1, x_2, \ldots, x_n)$. Строим вариацинный ряд выборки по
возрастанию: $x_(1) < x_(2) < \ldots < x_(n)$
$$\hat F(x) = $$

\begin{equation*}
\cap F(x) = \left\{\begin{aligned}
                   &0 &, x < x(1) \\
                   &k/n &, x(k) < x < x(k+1) \\
                   &1 &, x > x(n)\end{aligned}\right.
\end{equation*}

Иногда используют интервальные оценки, чаще всего в сочетании с точечными.

** Оценивание ряда распределения дискретной случайной величины.
Пусть $X$ -- дискретная случайная величина с конечным количеством
возможных значений. Необходимо построить оценку ряда распределения.

| $X$         | $X_1$           | $X_2$           | \ldots | $X_n$           |
|-------------+-----------------+-----------------+--------+-----------------|
| $\hat P(n)$ | $\hat P(X=x_1)$ | $\hat P(X=x_2)$ | \ldots | $\hat P(X=x_n)$ |

Часто строят статистический многоугольник распределения -- гистограмма.

** Оценивание плотности распределения непрерывной случайной величины
Наиболее часто используется, так называемый, гистограммный
метод. Пусть есть $(x_1,\ldots,x_n)$, и имеем $x_{min}, x_{max}$,
делим интервал $[x_{min},x_{max}]$ на части $I_1,\ldots I_n$; 

Например, $\hat P(x\in I_l) = \frac{n(x\subset I_l)}{n} = \hat P_l$;
Рассчитываем гистограмму: $G_l = \frac{\hat P_l}{\triangle
l}$. Строим гистограмму, для каждого интервала $I_l$ строится столбец
высоты $G_l$

Как правило выбирают интервалы постоянной длины $\triangle$. Возникает
вопрос как выбрать $\triangle$, часто рекомендуют выбирать так, чтобы
в одном интервале было не менее 5-6 значений из выборки. Нельзя ли
построить на основе гистограммного метода формальную процедуру, в
которой предел $\lim_{n\to\infty} G_l = f(x)$? Действительно такие
процедуры обеспечивающие сходимость можно построить, для этого должны
соблюдаться некоторые условия. Нужно $\triangle$ сделать зависимой от
$n$ ($\triangle_n \sim \frac{1}{\sqrt{n}}$), очевидного $\triangle$,
должно уменьшаться с ростом $n$, тогда $\lim_{n\to\infty}
G_n(x)=f(x)$.

\begin{equation*}
f(\alpha)=\left\{\begin{aligned}&0, \alpha < 0\\
 &1, 0 < \alpha<1 \\ &0, \alpha > 1\end{aligned}\right.
\end{equation*}

В современных языках программирования есть целочисленные случайные
величины. RTFM.

* Моделирование дискретных случайных величин.

X - случайная величина, ряд распределения $\{x_i, P_i\}$,
$i=\overline{1,n}$

| x_i |   |   |   |
|-----+---|---+---|
| P_i |   |   |   |

$$
 P(\sum_{k=0}^{n-1}P_k < \alpha < \sum_{k=0}^m P_i) = P_m
$$

\begin{verbatim}
int k;
double F;

a = frand();
F = 0;
for(k = 0; k < n; ++k)
{
    F += P[k];
    if(a < F) break;
}
return X[k]
\end{verbatim}

\begin{verbatim}
a = frand();
return (int) (a * n);
\end{verbatim}

** Случай счётного числа возможных значений.
Пример: распределение Пуассона. Возможные значения $x_k = k =
0,1,2\ldots$. $P_k = \frac{\lambda^k}{k!}e^{-\lambda}$. Для таких
вероятностей тактики:
1. Надо ограничить число возможных значений исходя из условия малости
   $P_k$ ($ < 10^{-10}$). И тогда применяется ранее рассмотренная
   схема.
2. Если возможно составить рекурентное соотношение вида $P_{k+1} =
   P_kr(k)$, то необходимо задать начальное условие $P_0$

\begin{verbatim}
a = frand();
F = P = P0;
k = 0;
for(;a >= F; ++k)
{
    P = P * r(k)
    F += P;
}
return k;
\end{verbatim}

Пусть $X, f(x), F(X)=\int_{-\infty}^xf(x)dx$
Есть 2 базовых метода:
1. Метод обратной функции. Идея в том, что нужно найти обратную
   функцию к функции распределения. Важный частный случей $X\sim
   R[a,b]$, $F(x) = \frac{x-a}{b-a} = \alpha$.
   Пример плотность распределения длины свободного пробега нейтрона в
   однородном веществе имеет вид $f(x) = \varsigma e^{-\varsigma x}, x
   > 0$. $F(x) = \int_0^x \varsigma e^{-\varsigma x} dx = 1 -
   e^{-\varsigma x} = \alpha$.
   $$ x = - \frac{\ln (1-\alpha)}{\varsigma} $$
2. Метод исключения
   $X \sim f(x), x\in[a,b]$; $M \geqslant f_max$
   Алгоритм:
   \begin{verbatim}
   do
   {
       s1 = a + (b - a) * frand();
       s2 = M * frand();
   } while(s2 > f(s1));
   \end{verbatim}

* Моделированное нормальной случайной величины
$X \sim N(a, \varsigma^2)$
$f(x) = \frac{1}{\sqrt(2\pi)\varsigma} e^{-\frac{x-a}{2\varsigma^2}}$
Применяют два специальных метода:
1. В силу центральной предельной теоремы $$ (\sum_{i=1}^{12}
   \alpha_i - 6) \sim N(0, 1) $$
   $$ \varsigma (\sum_{i=1}^{12} \alpha_i - 6) + a \sim N(a,
   \varsigma^2) $$
2. Метод порождающей пары:
   \begin{verbatim}
   a1 = frand();
   a2 = frand();
   x1 = sqrt(-2 * log(a1)) * sin(2*pi*a2); // ~ N(0, 1)
   x2 = sqrt(-2 * log(a1)) * cos(2*pi*a2); // ~ N(0, 1)
   \end{verbatim}
   
* Системы случайных величин
В рамках схемы распознавания на определённом этапе информация об
объекте представляется набором характеристик $x_1, \ldots, x_n$. Этот
набор рассматривают как систему случайных величин. Будем обозначать
$\bar X = (X_1,\ldots, X_n)$ -- система случайных
величин(вектор). Если маленькими буквами -- конкретная реализация
системы случайных величин. Надо определить:
1. Полное описание системы случ. в.
2. Неполное то же самое

** Система двух случайных величин
$n=2, \bar x = (x_1, x_2) = (x, y)$ -- случайный выбор на координатной
плоскости. Законы распределения системы двух случайных величин.
$F(x, y) = P((X < x),(Y < y))$. Свойства:
1. Неубывает по обеим компонентам.
2. $\lim_{x\to\infty} F(x,y) = F_2(y)$, $\lim_{y\to\infty} F(x, y) =
   F_1(x)$, $\lim_{x\to\infty,y\to\infty}F(x,y)=1$
3. $P((x_1<X<x_2),(y_1<Y<y_2)) = F(x_2,y_2) - F(x_1,y_2) - F(x_2,y_1) +
   F(x_1,y_1)$

** Ряд распределения дискретных случайных величин
Пусть $x$, $y$ --- случайные величины с какой-то хуйнёй $n_1$,
$n_2$. Ряд траляля труляля $(n_1,n_2)$ и бжж.

** ?
$$f(x,y) = \frac{\delta F(x,y)}{\delta x \delta y}$$
Часто $f(x,y)$ отображают в виде изолиний (линий равной вероятности).
$$\Gamma_{d_k} = \left\{ (x,y): f(x,y) = d_k \right\}, d_k = k
\triangle$$
$f(x,y)dx dy$ --- вероятность попадания с.в. $x$, $y$ в основание бесконечно
малого параллелепипеда со сторонами $dx$, $dy$, построенного рядом с
$x$, $y$.
$$P(x \in \mathbb D) = \iint_{D} f(x,y) dx dy$$
$$F(x,y) = \int_{-\infty}^{x} \int_{-\infty}^{y} f(x,y) dx dy$$

** Свойства плотности распределения
1. $f(x,y) \geqslant 0$
2. $\iint_{-\infty}^{\infty} f(x,y) dx dy = 1$

** Связь с законами распределения отдельных случайных величин, входящих в систему
1. $F_1(x) = F(x,\infty)$
2. $F_2(y) = F(\infty,y)$
3. $f_1(x) = \frac{dF_1(x)}{dx} = \int_{-\infty}^{\infty}f(x,y) dy$
4. $f_2(y) = \int_{-\infty}^{\infty} f(x,y) dx$

Обратная задача: можно ли найти $f(x,y)$, зная $f_1(x)$ и $f_2(y)$? В
общем случае нельзя.

** Условные законы распределения
1. $F(x/y) = P(X<x / Y<y)$ (условная функция)
2. $f(x/y) = \frac{dF(x/y)}{dx}$ (условная плотность)

Рассмотрим элемент вероятности:
$f(x,y) dx dy$ -- вероятность попадания $f$ в прямоугольник $dx\times
dy$. $f(x,y) dx dy = f_1(x) dx - f(y/x) dy$.

$$
f(x,y) = f_1(x) f(y/x) = f_2(y) f(x/y)
$$

Если $f(x/y)\neq f_1(x)$, то $x$ зависит от $y$, и не зависит в
противном случае.

Свойство зависимости/независимости взаимное (если одно з/нз, то и
другое то же самое.

Для независимых:
$$
f(x,y)=f_1(x)f_2(y)
$$
Так что для нз компонент можно в двумерном случае восстановить закон.

Числовые характеристики:
- Мода --- имеет смысл о ней говорить, это такая точка $(x,y)$, где
  $f(x,y)$ -- максимальна, можно говорить о унимодальных и
  полимодальных распределениях.
- Квантили и медианы --- не используются
- Моментные характеристики -- используются

Моменты порядка $(k, s)$:
Начальный: $$ m_{ks}=M[X^kY^s] =
\iint_{-\infty}{\infty}x^ks^kf(x,y)dx dy $$
Центральный: $$ \mu_{ks}=M[(X-\bar x)^k(Y-\bar y)^s], k,s =
0,1,2\ldots \infty$$

Часто используют понятие суммарных моментов порядка $(k+s)$
$$m_{10}=M[X^1Y^0]-M[X] = m_0=\bar x$$
$$m_{01}=\bar x$$

Центральные моменты:
$$\mu_{20}=M[(X-\bar x)^2(Y-\bar y)^2]=M[(X-\bar x)^2] =
\varsigma^2_x=D_x$$
Описывает разброс компоненты X
$$\mu_{02}=D_y$$
$$\mu_{11}=M[(X-\bar x)(Y-\bar y)]=K_{xy}$$
корреляционный момент между $x$ и $y$
Пусть х и у независимы, тогда $$K_{xy}=\iint (X-\bar x)(Y-\bar
y)f_1(x)f_2(y)dx dy = 0 \cdot 0 = 0$$
Теперь случай зависимых:
$r_{xy}=\frac{K_{xy}}{\varsigma_x\varsigma_y}$ -- коэффициент
корреляции между х и у.

Важный нюанс:
Мы показали, что из независимости $x$ и $y$ следует некорреллируемость
($K_{xy}=r_{xy}=0$). Вопрос теперь а следует ли это в обратном
направлении?

Нет не следует в общем случае. Но пример если плотность распределения
в круге, $f(x,y)=c$, легко показать, что $K_{xy}=0$, но $x$ и $y$ --
зависимы.  
$f(y/x_1), f(y/x_2)$ какие-то прямоугольнички, т.е. $x_1$ и
$x_2$ зависимы.
Что чувствует коэффициент коррелляции? Грамотный ответ таков: он
чувствует наличие и степень выраженности ЛИНЕЙНОЙ СВЯЗИ между
случайными величинами $x$ и $y$.
Предельный случай выраженности линейной зависимости достигается при
связи законом $Y = aX + b$, где $X$, $Y$ --- с.с. и
с.у. соответственно.

** ДВУМЕРНЫИ АЦЕНКИ
Очень желательно помимо числовых значений привести распределение
выборочных точек.

* Система произвольного числа случайных величин
$\bar x = (x_1,\ldots, x_n)^{-1}$, $n \geqslant 2$. Полное описание
задаётся $F(\bar x)=P((X_1 < x_1)(X_2 < x_2)\ldots(X_n < x_n))$ --
ф-ия распределения. Плотность распределения $f(\bar x) =
\frac{\delta^n F(\bar x)}{\delta x_1\ldots \delta x_n}$ св-ва очевидны
и аналогичны одномерному случаю.

** Числовые характеристики
1. Мода --- да, применяется.
2. Моменты --- применяются.
   В общем случае следует говорить о моментах порядка
   $(k_1,k_2,\ldots,k_n)$. Часто используют суммарные моменты $\sum
   k_i = S$. На практике ограничиваются суммарными моментами порядков
   1 и 2. $\bar x_k = M[X_k] = \int x_k f(x_1,\ldots,x_n) dx_1\ldots
   dx_n$, $\vec{\bar x} = (\bar x_1, \ldots, \bar x_n)$. Это были
   характеристики положения.
3. n -- дисперсии компонент случайного вектора. $D_k = M[(X_k-\bar
   x)^2]=K_{kk}$ -- это характеристики рассеивания от отдельных
   компонент.
4. n(n-1) -- корреляционных моментов всех возможных пар компонент
   $$ K_{ij} = M[(X_i - \bar x_i)(X_j - \bar x_j)] $$ чтото +
   рассеивание компонент от своих средних. 3 и 4 часто объединяют в
   корреляционную матрицу. $$ K = \{k_{ij}\} $$ она симметричная. Если
   $x_1,\ldots, x_n$ -- не коррелированные, то K -- диагональная. Для
   акцентированного представления корреляционных связей часто
   используют нормированную корреляционную матрицу. $r_{ij} =
   \frac{k_{ij}}{\varsigma_i\varsigma_j}$, получаем что на диагонали
   единицы, $|r_{ij}| < 1$.

** Нормальный закон распределения системы случайных величин
Говорят, что $\vec X \sim N(\vec a, B)$, если 
 $f(\vec x) =$
 $\frac{1}{(2\pi)^{\frac{n}{2}}|B|^{\frac{1}{2}}}$
 $e^{-\frac{1}{2}(\vec x - \vec c) B^{-1} (\vec x - \vec a)} =$
 $\frac{1}{(2\pi)^\frac{n}{2} |B|^{\frac{1}{2}}}$
 $e^{-\frac{1}{2}\sum_{i,j}(x_i - a_i) B^{-1}_{ij}(x_i-a_j)}$,
где $\vec a$ -- вектор параметров. B --
положительно определённая матрица параметров, т.е. $\vec x B \vec x
\geqslant 0$. Известно, что если исходная матрица положительно
определённая, то и обратная тоже. Рассчитаем числовые характеристики.

1. $\bar x_1 = a_1, \bar x_2 = a_2, \ldots, \bar x_n = a_n$ или $\vec
   x = \vec a$, где $a$ -- вектор случайных значений всех признаков
   (можно показать, что вектор $\vec a$ -- мода распределения)
2. $K_{ij} = b_{ij}$, при $\forall i,j$, т.е. $||K||=||B||$, как и в
   случае скалярных нормальных величин оказывается, что плотность
   распределения полностью определяется знанием только моментов первых
   двух суммарных порядков (1 и 2). Задача оценивания плотности $\hat
   f(\vec x)$ по опытным данным может быть сведена к оцениванию по выборке $(\vec
   x^1, \vec x^2, \ldots x^n)$ при $\hat{\vec a}$ и $\hat B$

Вернёмся к проблеме независимость --- некоррелируемость. Для
нормального закона из некоррелируемости следует независимость. 

Доказательство:
$\vec x \sim N(\vec a, B)$ -- некоррелируемы $k_{ii}=D_i$, $k_{ij} =
0, i\neq j$, $k_{ij}^{-1}=\frac{A_{ij}}{|K|}$.
$$               
 (K^{-1}) =\left(\begin{array}{ccccc}
 \frac{1}{D_1} & 0             & 0      & \ldots & 0      \\
 0             & \frac{1}{D_2} & 0      & \ldots & 0      \\
 \vdots        & \vdots        & \vdots & \vdots & \vdots \\
 0             & 0             & 0      & \ldots & \frac{1}{D_n}
 \end{array}\right)
$$

$f(\vec x) =$
$\frac{1}{(2\pi)^{\frac{n}{2}} \prod\sqrt{D_i}}$
$e^{-\frac{1}{2}\sum\frac{(x_i - a_i)^2}{D_i}} =$
$\prod^n_{i=1}\frac{1}{\sqrt{2\pi} \varsigma_i}$
$e^{-\frac{1}{2}\frac{(x_i - a_i)^2}{\varsigma_i}} =$
$\prod_{i=1}^n f(x_i)$, что есть следствие
независимости компонент $\vec x$.

** Нормальный закон на плоскости
$n=2, \vec X = (X, Y)^T, \vec a = (\bar x, \bar y)^T$,
$B = K = \left(\begin{array}{cc}\varsigma_x^2 & K_{xy} \\ K_{xy} & \varsigma_y^2\end{array}\right)x$
$K_{xy} = r\sigma_x\sigma_y$, где r -- коэффициент корреляции.
$|K|=\varsigma_x^2\varsigma_y^2 - r^2\varsigma_x^2\varsigma_y^2 =
      \varsigma_x^2\varsigma_y^2(1-r^2)$
$K_{11}^{-1} = \frac{\varsigma^2_y}{|K|} =
      \frac{1}{\varsigma_x^2(1-r^2)}$
ВСЕ ПО ПИЗДЕ ПОШЛО
$f(x,y)=$
$\frac{1}{2\pi\varsigma_x\varsigma_y\sqrt{1-r^2}}$
$e^{-\frac{1}{2(1-r^2)}[\frac{(x-\bar x)^2}{\varsigma_x^2} - \frac{2r(x-\bar x)(y - \bar y)}{\varsigma_x\varsigma_y} + \frac{(y-\bar y)^2}{\varsigma_y}]}$

Теперь зарисуем с помощью изолиний
$\Gamma = \{(x,y): f(x,y) = d\};$
$\frac{(x- \bar x)^2}{\varsigma_x^2} - \frac{2r(x-\bar x)(y - \bar
y)}{\varsigma_x\varsigma_y} + \frac{(y-\bar y)^2}{\varsigma_y^2} =
\lambda^2_d$ -- это эллипс с центром в точке $(\bar x, \bar y)$

[ Картинка с наклонённым эллипсом, вытянутым и с главной осью под
углом. Важное условие относительно наклона: $\tan 2\alpha =
\frac{2r\varsigma_x\varsigma_y}{\varsigma_x^2 - \varsigma_y^2}$

Случай некоррелированной системы $r=0, \tan 2\alpha = 0$, т.е. $\alpha
= 0$ или $\alpha = \frac{\pi}{2}$. 

Если $r \ne 0$, то наклон под углами. Если при этом ещё $\varsigma_x^2
= \varsigma_y^2$, то $\alpha = 45$. 

Если $r = 0, \varsigma_x^2 = \varsigma_y^2$, то окружность.

Если $r = +-1$, +1 и -1 -- прямая под углами. ]

* Моделирование n-мерной случайной величины
Имеется $\vec X$, для которой известны $f(\vec X)$ или $F(\vec
X)$. Нужна компьютерная процедура, которая возвращает каждый раз
случайный вектор $\vec x$, соответствующий $\vec X$ с заданным законом
(см. начало абзаца).

Здесь можно распространить моделирование скалярных СВ:
- метод обратной ф-ии, $(x, y) = F^{-1}(\xi)$, есть сложность в
  нахождении обратной ф-ии.
- метод исключения. Есть $f(x,y)$ \ldots Сложность, что в случае
  больших $n > 2$ много отбракованных точек, что увеличивает время
  моделирования. Есть приём для увеличения вычислительной
  эффективности $f(\vec x)=f(x_1)f(x_2/x_1)\ldots f(x_n/x_{n-1}\ldots
  x_1)$. Для многомерных законов распределения обычно придумывают
  специализированные версии, которые работают гораздо быстрее.

** Нормальное распределение
Для случая $X \sim N(\vec m, K)$, есть специальная процедура:
1. Моделируем вспомогательный вектор $\vec \eta=(\eta_1\ldots
   \eta_n)^+$, при этом $\eta_i \sim = N(0, 1)$
2. Формируем требуемый псевдослучайный вектор $\vec x = A\vec\eta
   +\vec m$.
   Значит $A$ -- матрица вида
   $A = \left(\begin{array}{cccc} a_{11} & 0 & \ldots & 0 \\ a_{21} & a_{12} & \ldots & 0 \\ a_{n1} & a_{n2} & \ldots & a_{nn}\end{array}\right)$
   $$ a_{ij} =
   \frac{K_{ij}-\sum_{k=1}^{j-1}a_{ik}a_{jk}}{\sqrt{K_{ji}-\sum_{k=1}^{j-1}a_{jk}^2}};
   1\leqslant j \leqslant i \leqslant n $$

   Если $n = 2$, $a_{11} = \sqrt{K_{11}}$,
   $a_{21}=\frac{K_{12}}{a_11}=\frac{K_{12}}{\sqrt{K_11}}$,
   $a_{22}=\sqrt{K_{12}-a_21^2}=\sqrt{K_{12}(1 - \frac{1}{\sqrt{K_11}})}$

* Функции случайных величин
$Y=\varphi(\vec x), \vec x=(x_1,\ldots,x_n)^+$
Пример:
Параллелипипед, линейка, весы, измерим плотность $\rho$
$\rho=\frac{m}{V}=\frac{m}{abc};$

Знаем закон распределения $\vec X$, задачи: 
1. числовые характеристики Y.
2. Закон распределения Y.

Знаем числовые характеристики $\vec X$, получить числовые
характеристики $Y$.

** Числовые характеристики Y, при известном законе $\vec X$
Ограничиваясь только моментами.
$$ m_k = M[\varphi(\vec X)] = \int_{-\infty}^{\infty} \varphi^k(\vec x)f(\vec
x) d\vec x $$

** Закон распределения Y, при известном законе $\vec X$
Известно $f(\vec x)$, а надо найти $g(y)$.
*** Для начала одномерный случай для $\vec x, n = 1, x$.
Пусть $\varphi(x)$ -- монотонна, на области задания $\vec x$: $[a,b]$,
$G(y) = P(Y < y) = P(X < \varphi^{-1}(y)) = \int_{a}^{\psi(y)}f(x)dx$, $\psi(y)=\varphi^{-1}$.
$$g(y) = \frac{dG(y)}{dy} = f(\psi(Y))\psi'(y)$$

Для монотонно убывающей $\varphi(y)$:
$$ g(y)=-f(\psi(y))\psi'(y) $$
В общем случае можно использовать формулу:
$$ g(y)= f(\psi(y))|\psi'(y)| $$
Что делать в общем случае? (несколько участков монотонности).
$$ g(y) = \sum f(\psi_i(y)) |\psi_i'(y)| $$
*** Функция двух случайных величин
$G(z) = P(Z < z) = P((x,y) \in D(z)) = \iint_{D(z)} f(x,y) dx dy;$
$g(z) = G'(z)$
Важный пример:
$z = x + y$, имеем f(x,y), надо g(z). И тогда применив подход можно
получить $ g(z) = \int_{-\infty}^{\infty}f(z-y,y)dy =
\int_{-\infty}^{\infty}f(x,z-x)dx $

Частный случай, если $x$ и $y$ -- независимые ($f(x,y) = f_1(x)f_2(y)$, то
$$ g(z) = \int_{-\infty}{\infty}f_1(x)f_2(z-x)dx =
\int_{-\infty}^{\infty} f_1(z-y)f_2(y) dy = [f_1 * f_2] $$ --
свёртка

$x \sim R[0, 1]$ и $z = x_1 + x_2$ <...>

*** Определение числовых характеристик Y по числовым характеристикам X.
Задача имеет решение только для некоторых законах X. Теоремы о
числовых характеристиках:
1. Неслучайная величина Y = C. $f(y)=\delta(y-C)$
   $M[C] = C$, $D[C] = 0$
2. Y = cX, $\bar Y = c\bar X$, $D_y = \varsigma_y^2 = c^2 D_x$,
   $\varsigma_y = |c|\varsigma_x$
3. Y = x_1 + x_2, $\bar y = \bar x_1 + \bar x_2$, $D_y = D_{x_1} +
   D_{x_2} + 2 K_{x_1x_2}$. Если $x_1$ и $x_2$ -- независимы, то
   $D_y = D_{x_1}+D_{x_2}$
4. $Y = \sum x_i$, $\bar y = \sum \bar x_i$, $D_{y} = \sum D_{x_{i}} +
   2 \sum_{i < j}K_{ij}$. Для независимых последнего члена нету.
5. Y = x_1x_2, $\bar y = \bar x_1 \bar x_2 + K_{x_1x_2}$, $D_y =
   D_{x_1}D_{x_2} + \bar x_1^2 D_{x_1} + \bar x_2^2 D_{x_2}$, если
   центрированный случай, то $D_y = D_{x_1}D_{x_2}

* Случайные функции
Случайные события $\Rightarrow$ Случайные величины ($X, f(x), F(x)$,
числовые характеристики) $\Rightarrow$
Случайные явления, результат которых фиксируется как система случайных
величин ($\vec x, f(\vec x), F(\vec x)$) $\Rightarrow$ случайные
функции.

*Случайная функция* --- это функция, которая в результате эксперимента
принимает вид, неизвестно какой.

Обозначения: $X(t), X(r), X(\vec r)$. Конкретный вид функции,
полученной в одном эксперименте называется реализацией случайной
функции ($x(t)$). Совокупность реализаций --- ансамбль
реализаций. Примеры:
1. Речевой сигнал ($X(t)$).
2. Профиль температуры воды 11 августа на набережной.
3. Спутниковый снимок поверхности.

Если аргумент --- время, то X($t$) --- случайный процесс. Если аргумент
--- пространственная величина ($x,y,z,\vec r$), $X(\vec r)$ ---
случайное поле. $X(\vec r, t)$ --- пространственно-временное поле.

** Классификация случайных функций с точки зрения аргумента и значения функции.

1. Случайные процессы общего вида. $X(t)$, $t$ --- непрерывный временной
   аргумент, $x$ --- непрерывна.
2. Дискретные СП. $t$ --- непрерывна, $x$ --- дискретна.
3. Случайные ряды (последовательности). $t$ --- дискретна, $x$ --- непрерывна.
4. Дискретные случайные последовательности. $t$, $x$ --- дискретны.

Рассмотрим СП $X(t)$ ($x,t$ --- непрерывны).
В момент $t_1: x(t)$ -- обычная случайная величина. Отсюда плотность:
$f_1(x;t_1)$, $\forall t_1$. Но! Этого мало. Фиксируя 2 точки $t_1$ и
$t_2$; отсюда две случайные величины: $x(t_1), x(t_2)$. Имеем две
плотности распределнения $f_2(x_1,x_2;t_1,t_2)$. Так и для трёх
$f_3(x_1,x_2,x_3;t_1,t_2,t_3)$. Случайный процесс $X(t)$ полностью
описан, если известны все конечные наборы плотностей
$f_n(x_1,\ldots,x_n;t_1,\ldots,t_n)$, $forall t_1,\ldots,t_n$.

** Упрощение модели случайных процессов
1. Процесс с 
   $$f_n(x_1,\ldots,x_n;t_1,\ldots,t_n) = \prod_{i=1}^n f_i(x_i;t_i)$$
   Т.е. достаточно знания одномерных $f_1(x;t),\forall t$
2. Марковские процессы (процессы без последействия). Известно, что в
   общем случае 
   $$f_n(x_1,\ldots,x_n;t_1,\ldots,t_n)=f_{n-1}(x_1,\ldots,x_{n-1};t_1,\ldots,t_{n-1})
   \cdot f(x_n;t_n/x_1\ldots x_{n-1};t_1\ldots t_{n-1})$$. Тогда
   $$f_n(x_1,\ldots,x_n;t_1,\ldots,t_n) = f_1(x_1;t_1)\cdot \prod_{i=2}^n
   f(x_i; t_i/x_{i-1}; t_{i-1})$$. Т.е. нам надо знать две $f$:
   $f_1(x;t),\forall t$, и условные вероятности.
3. Стационарные СП (ССП) (для полей --- однородные случайные
   поля). Идея: вероятностные свойства не меняются со временем.
   Это означает, что $$\forall tau,
   f_n(x_1,\ldots,x_n;t_1,\ldots,t_n)=f_n(x_1,\ldots,x_n;t_1+\tau,\ldots
   t_n + \tau)$$
   
Что это упрощает? 
$f_1(x_1;t_1)=f_1(x_1)$ -- не зависит от времени.
$f_2(x_1,x_2;t_1,t_n) = f_2(x_1,x_2;\tau=t_2-t_1) =
f_2(x_1,x_2;\tau);$

** Числовые характеристики случайных функций
Моментные характеристики малых порядков:
1. Математическое ожидание СП: $\bar x(t) = M[x(t)] =
   \int_{-\infty}{\infty} x f_1(x;t) dx$;
2. Дисперсия случайного процесса $D_x(f) =
   \varsigma^2_x(t)=M[(x(t)-\bar x(t))] =
   \int_{-\infty}{\infty}(x-\bar x(t))^2f_1(x;t)dx$. $\varsigma_x (t)=
   \sqrt(D_x(t))$ --- среднеквадратичное отклонение.
3. Асимметрия $\gamma_x(t)=\frac{M[(X(t) - \bar x(t))^3]}{\varsigma_{x(t)}^3}$
4. Коэффициент эксцесса 
   $\kappa_x(t)=\frac{M[(X(t)-\bar x(t))^4]}{\varsigma_{x(t)}^4-3}$

** Что-то основанное на знании плотностей 2-ого порядка

$K(t_1,t_2) = M[(x(t_1) - \bar x(t_1))(x(t_2) - \bar x(t_2))] = 
\int (x_1 - \bar x(t_1))(x_2 - \bar x(t_2))f_2(x_1,x_2;t_1,t_2)dx_1
dx_2$; -- это корреляционная функция. Часто рассматривают
нормированную корреляционную функцию $r_x(t_1, t_2) =
\frac{K(t_1,t_2)}{\varsigma_x(t_2)\varsigma(t_1)}$

N.B.: О взаимной корреляционной функции, пусть $X(t), Y(t)$ -- два
случайных процесса. $K_{xy}(t_1, t_2)=M[(x(t_1)-\bar
x(t_1))(y(t_2)-\bar y(t_2))]$. Часто используют нормированную взаимную
корреляционную функцию: $r_{xy}(t_1;t_2) = \frac{K_{xy}(t_1, t-2)}{\varsigma_x(t_1)\varsigma_y(t_2)}$
