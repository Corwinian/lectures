#+TITLE:        Распознавание образов
#+AUTHOR:       Дмитрий Кравцов
#+EMAIL:        idkravitz@gmail.com
#+DATE:         11 февраля 2011 года.
#+DESCRIPTION:  набор лекций по (см. тайтл) 
#+LANGUAGE:     russian
#+LATEX_HEADER: \usepackage[russian]{babel} \usepackage[T2A]{fontenc} \usepackage[utf8]{inputenc}
#+TAGS: PatternRecognition

* Введение в распознавание образов

Распознавание образов -- отнесение наблюдаемого объекта (процесса,
явления) к одному из нескольких классов. Способность к распознаванию
образов это одно из свойств человека и живых существ. В целом говоря о
проблеме распознавания образов имеют ввиду 2 класса задач:

1. Изучение способности человека к распознаванию.
2. Развитие теории и методов построения устройств предназначенных для
   решения задач распознавания.

Распознавание образов -- наука, занимающаяся проблемой создания и
технических и программных устройств распознавания

** История

1. История (началось с 20 века) -- теория статистических решений.
2. 1950г. -- теория искусственных нейронных сетей. Именно тогда в рамках тех задач и родилось название
   класса задач -- распознавание образов.
3. С 1980г. возникли серьёзные продвижения в нейросетевой парадигме, появления множество методов и
   статей, описывающих эти методы.

** Решаемые задачи

Задача распознавания образов может активно перетекать в задачу распознавания сцен (изображения лиц,
собраний, людей\ldots). Сложные решения обычно базируются на простых
решениях.\\
#+LABEL pic1:simple_pr
#+CAPTION: простой решатель
#+ATTR_LaTeX: width=480px
[[./images/pic1.png]]

По приведённой схеме работают простые системы распознавания образов. Например задача распознавания
текста может и не быть простой, если модель решения задачи усложнена (выделение области текста, выпил слов
и т.д.). Для описания объекта достаточно лишь определить к какому классу он относится.

*** Пример 1
Объект: кристалл соли (NaCl). Описание объекта -- положения атомов в кристаллической решётке и прочие 
параметры, поэтому решить на ЭВМ не представляется возможным. Поэтому задача ставится например так:
1. Соль это или сахар.
2. Если соль, то мелкого или крупного помола.


*** Пример 2
Объект: Человек.\\
Задача распознавания 1: ребёнок это или взрослый.\\
Задача распознавания 2: спокойный это человек или возбуждённый.\\
Задача распознавания 3: Вася или Петя.

Датчик (или рецептор) осуществляет первичное восприятие образов. Для разных задач распознавания могут
применяться разные датчики. Если речь идёт о человеке то его рецепторы: глаза, уши, пальцы\ldots Если это
техническая система -- видеокамера, цифровой фотоаппарат\ldots

** Информационные структуры, которые могут восприниматься датчиками

Первичные данные - данные, воспринимаемые датчиками.

- некий числовой параметр (температура человека).
- группа параметров (температура тела, пульс, давление).
- случайный сигнал (ЭЭГ (электроэнцефалограмма) -- замер разности потенциалов между точками головы 
  во времени).
- система случайных сигналов (ЭКГ (большое количество точек измерения) -- то же что и выше но больше
  точек замера).
- изображение ($f(x,y)$ -- непрерывный случай и $\{f_{ji}\}, j=1,\ldots, n, i=1,\ldots, k$).
- система изображений (многозональные спутниковые снимки).
- видео ($f(x,y,t)$).
  
* Прикладная теория вероятности

*Теория вероятности* -- математическая наука, изучающая закономерности в
случайных явлениях. *Случайное явление* -- явление, которое при
неоднократном воспроизведении одного и того же опыта всякий раз
протекает несколько по разному.

Насколько распространены случайные явления? Они присутствуют
повсеместно. Пример: стрельба из пушки по цели. Как попасть в цель?
Нужно составить некоторую модель полёта, воспользовавшись методами из
механики. При просчёте по простейшей модели реальный снаряд упадёт
раньше (ближе) чем рассчитано, тогда можно ввести в расчёт учёт
сопротивления воздуха (форма, баллистический коэффициент). Тогда
траектория станет ещё более точной, но мы всё равно получим набор
недетерминированных траекторий. Словом почти всегда есть элемент
случайности, который не удаётся устранить. 

1. *Случайные события* -- всякий факт, который в результате опыта может
   произойти или не произойти. $A \to P(A)$

2. *Случайная величина* -- величина, принимающая в результате опыта
   значение, заранее неизвестно какое. Сабж бывает дискретным
   (область конечна или счётна) и непрерывным. Полное описание
   случайной величины -- закон распределения вероятности, который
   указывает какие возможные значения более возможны и какие
   менее. Для случайной величины есть универсальный вид *закона
   распределения* -- функция распределения $F(x)$. Кроме того для
   дискретных случайных величин распространена форма задания закона
   распределения в виде ряда распределения (таблица вероятностей). Для
   непрерывной случайной величины используют часто $f(x)$ -- *плотность
   распределения*.

3. Опыты, результаты которых фиксируются в виде *набора (системы)
   случайных величин* ($\bar x = (x_1,\ldots,x_n)$).
   Примеры важных численных характеристик: среднее значение случайной
   величины $\bar x$, дисперсия $D(\bar x)$, корреляционные величины.
   Полное описание -- закон распределения $f(\bar x)$ или $F(\bar
   x)$. Числовые характеристики представляют собой неполное описание.

4. Случайные функции ($X(t)$) (..переписать..)

** Случайные события

*Достоверное событие* -- событие, которое обязательно происходит во
всяком опыте ($U, \Omega$). Событие $V, \varnothing$ -- *невозможное*
событие. Если есть событие $A$, то $\bar A$ -- *дополнительное* к $A$
событие. Очень часто пользуются графической иллюстрацией на
плоскости. События $A$ и $B$ *несовместны*, если они не могут произойти
одновременно. $\{A_1,\ldots,A_n\}$ -- группа событий, является
несовместной, если любая пара различных событий из неё являются
несовместной. Очевидное свойство -- $A$ и $\bar A$ несовместны. Полная
группа событий $\{A_1,\ldots,A_n\}$, если в результате всякого опыта
произойдёт хотя бы одно из событий группы. Полная группа несовместных
событий -- полная, несовместная группа.
*** Отношения между событиями
+ *Включение*: $A \subset B$. $A$ происходит всякий раз, когда
   происходит $B$
+ *Отношение эквивалентности*: $A = B$, если $A \subset B$ и $B
   \subset A$.
*** Операции над событиями
+ *Сумма*: $C=A+B$, $C$ происходит тогда и только тогда, когда
  происходит либо $A$ либо $B$

+ *Умножение*: $C = AB$ происходит тогда и только тогда, когда
  происходит и $A$ и $B$
+ *Разность*: $C = A - B = A\bar B$

$A$ и $B$ несовместны, если $AB = \varnothing$.
$\{A_i\}$ -- полная группа, если $\sum A_i = \Omega$.
$\{A_i\}$ -- полная группа несовместных событий, если `

События могут быть составными и элементарными. Составные могут быть
представлены через другие события. Элементарные являются
неразложимыми (обозначаются например \omega). Когда рассматривают или
расписывают математически некоторый случайный опыт всегда первым делом
описывают пространство элементарных событий (ПЭС) -- полная группа
несовместных элементарных событий. Достоверное событие \Omega состоит
из всех событий из ПЭС. Различают дискретные и непрерывные ПЭС.
Дискретное:
1. Конечное число исходов. \Omega =
   \{\omega_1,\omega_2,\ldots,\omega_n\}
2. Счётное число исходов. $\Omega = \{\omega_1,\omega_2,\ldots\}$
   (например бросание кости до первой 6)

Непрерывное ПЭС:
Множество элементарных исходов не счётно. Например стрельба по мишени,
когда результат -- пара координат, куда попала пуля,
т.е. $\omega=(x,y), \Omega=\{\omega:-\infty<x,y<\infty\}$

Далее необходимо определить алгебру событий (пространство
событий). Множество событий U, составленное из ПЭС, которое может
интересовать нас с точки зрения расчёта вероятности этих событий. В U
обязательно должно быть:
1. Нулевой и единичный элементы $(\varnothing, \Omega)$.
2. Для $\forall A \in U \exists \bar A \in U$
3. Для $\forall \{A_i \in U\}_{i=\overline{1,\infty}} \sum A_i \in U, \prod
   A_i \in U$
Измеримые подмножества из ПЭС составляют Барелевскую алгебру.
Два крайних случая множества U:
1. U = $\{\varnothing,\Omega\}$
2. U = все возможные подмножества ПЭС
Двойка $\{\Omega, U\}$ -- измеримое пространство. $\forall A \in U,
P(A)$ - вероятность события A. 

Вероятностью P называют числовую функцию, определённую на элементах
\sigma-алгебре событий, удовлетворяющую следующим аксиомам:
1. $P(A) \geqslant 0, \forall A \in U$
2. $P(\Omega)=1$
3. $P(\sum_{i=1}^n A_i)=\sum_{i=1}^n P(A_i)$, если \{A_i\} --
   несовместны.
4. $P(\sum_{u=1}^\infty A_i) = \sum_{i=1}^\infty P(A_i)$, если \{A_i\}
   -- несовместны.
   
** Вероятностое пространство

Тройка (\Omega, U, P(A)), тут \Omega - ПЭС. Основная цель -- отыскание
P(A).
Частота и статистическая вероятность. Пусть A и B -- совместны и
оказалось, что число осуществления A >> числа осуществления B. Тогда у
нас большие основания полагать, что P(A) > P(B).

Пусть A -- некоторое событие. $\nu_n(A) = \frac{\nu(A)}{n}$ -- частота
события А. $\nu(\varnothing)=0,\nu(\Omega)=1$, $\nu_n(A)\geqslant 0$,
$\nu_n(A+B)=\nu_n(A) + \nu_n(B) - \nu_n(A\cap B)$. Проведём 2 раза по
n опытов: $\nu_A'\neq\nu_A?$. При $n\to\infty \Rightarrow |\nu_A' - nu_A| \to
0$ предельное значение $\nu_A = P(A)$.

Факт стремления $\nu_n(A)\to P(A)$ был установлен Якобом Бернули, и
этот факт стал известен как Закон Больших Чисел $$\lim_{n\to\infty}
\nu_n(A)=P(A)$$

Вероятностная сходимость отличается от обычной. Для $\forall
\varepsilon > 0$ справедливо
$\lim_{n\to\infty}P(|\nu_n(A)-P(A)|<\varepsilon)=1$. Статистическая
вероятность:
$\hat P(A) = \nu_n(A) = \frac{n(A)}{n}$

$\Delta P(A)=|\nu_n(A) - P(A)|$, $\frac{\Delta P(A)}{P(A)}$ -- относительная ошибка, при этом $\Delta
P(A) \sim P(A)\frac{1}{\sqrt{n}}$. 

* Классическая вероятность
Вероятность события A определяется отношением числа исходов,
благоприятных событию A к общему числу *равновозможных* исходов опыта. 
$$
P(A)=\frac{n(A)}{n}
$$

Спроецируем классические вероятности на аксиоматическое определение
вероятности
1. ПЭС - конечное, $\Omega=(\omega_1,\ldots,\omega_n)$.
2. $U$ - обычная алгера, включающая все комбинации элементарных
   исходов ($|U|=2^n$)
3. $P(\omega_k)=\frac{1}{n},\forall k=\overline{1,n}$. $\forall A\in
   U$ соответствует некоторая совокупность элементарных исходов
   (например $\omega_3,\omega_7,\omega_{11}$). Тогда по 3-ей аксиоме
   вероятности $P(A)=\sum_{\omega_i\in A} P(\omega_i)=
   \sum_{n(A)}\frac{1}{n}=\frac{n(A)}{n}$

Пример есть 5 шаров (3 белых, 2 чёрных). Элементарное событие --
вытащили шар. $P(A)=\frac{3}{5}$, $P(B)=\frac{2}{5}$. Если вытащили 2
шара $P(A)=\frac{C^2_3}{C^2_5}=\frac{3!3!2!}{2!5!}=0.3$

Предположим, что реализована схема с возвращением шаром, тогда, если A
-- оба белые: $P(A)=\frac{3^2}{5^2}=\frac{9}{25}=0.36$

** Комбинаторные схемы
1. Выбор r элементов из групп с числами элементов
   $n_1,n_2,\ldots,n_r$. $N=n_1\cdot n_2\cdot\ldots\cdot n_r$
2. Выбор r элементов из одной группы с возвращением (эквивалентно r
   групп по n элементов), $N=n^r$. Эта задача эквивалентна размещению
   r элементов по n ящикам
3. Выбор r элементов из  n элементов по схеме без возвращения \equiv
   размещение r элементов по n ящикам, но не более одного элемента в
   ящик. $N=n(n-1)\cdot\ldots\cdot (n-r+1)=\frac{n!}{(n-r)!}=A^r_n$ --
   число размещений из n по r. Перестановка: $N=n!$
4. Выбор r неразличимых элементов из n элементов
   $N = \frac{A^r_n}{r!} = \frac{n!}{(n-r)!r!} = C^r_n$

** Геометрическая вероятность
Возникает когда выбор наудачу точки из некоторой области $\Omega$ в
некотором пространстве $R$. Событие A происходит если $A\in
\Omega$. Объём $A = \mu(A)$, $\Omega = \mu(\Omega)$, $P(A) =
\frac{\mu(A)}{\mu(\Omega)}$. Если работаем с $R^1$, то объём -- длина
отрезка. $R^2$ -- площадь.

1. ПЭС -- множество точек $R^n\subset \Omega$.
2. U -- множество всех подобластей, лежащих в $\Omega$ и имеющих
   ненулевой объём.
3.  $P(A) \sim \mu(A)$ \\
   $P(\Omega)=1 \sim \mu(\Omega)$

Пример: 2 человека договорились встретиться между $13^{00}$ и
$14^{00}$ обязательно каждый из них придёт в этом
интервале. Договорились, что ждут друг друга не более 10 минут.

$\Omega=\{(\xi,\eta): 0\leqslant \xi, \eta \leqslant 60\}$,\\
$\mu(\Omega)=60^2$, $A=\{(\xi, \eta): |\xi - \eta| \leqslant
10\}$. Рисуночек, $\mu(A)=60^2 - 50^2$, $P(A) = 1 -
\frac{50^2}{60^2}=\frac{11}{36}$

** Косвенные методы нахождения вероятностей
A -- сложное событие. P(A)=?
B,C,D -- более простые события, вероятности их могут быть легко
найдены. Тогда мы можем предположить, что событие A можно с помощью
правил алгебры событий представить через события B, C, D (A=F(B,C,D))
-- в этой конструкции будут 2 базовые операции: сложение и умножение
событий. Если мы будем знать как находить $P(B+C)$ -- теорема сложения
вероятностей, $P(BC)$ -- теорема умножения вероятностей.

*** Теорема сложения
P(A+B)=P(A)+P(B)-P(AB)

*** Теорема умножения
Введём понятие условной вероятности: P(A/B) -- условная вероятность
события A, при условии, что событие B уже произошло. Если
$P(A/B)=P(A)$, то A не зависит от B. Если $P(A/B)=P(A)$, то
$P(B/A)=P(B)$.

P(AB) = P(A) P(B/A)=P(B) P(A/B)
$P(A_1,\ldots, A_n) = P(A_1)P(A_2/A_1)P(A_3/A_1A_2)\ldots
P(A_n/A_1\ldots A_{n-1}$

Для независимых:
$P(AB) = P(A)P(B)$
$P(\prod A_i)=\prod_{i=1}^n P(A_i)$

*Пример:*\\
w - white, b - black.
 $P(ww) = P(1w)P(2w/1w) = \frac{3}{5}\cdot\frac{2}{4} = 0.3$ \\
*Если случай с возвращением:* $P(ww)=P(1w)P(2w) = \frac{9}{25}$

* Два важных следствия из теорем сложения и произведения

** Формула полных вероятностей

Пусть $H_1,\ldots,H_n$ -- полная группа несовместных событий
(гипотез). Пусть событие $A$ -- событие, которое происходит совместно
с одной из гипотез. Тогда имеем замечательную формулу:

$$
    P(A) = \sum_{k=1}^n P(H_k)P(A)
$$

*Вывод формулы*: $A=AH_1 + AH_2 + \ldots + AH_n$ (все события в сумме
являются несовместными).

Пример. Имеются 3 урны, в первой: 2 белых + 1 чёрный, во второй: 3
белых и 1 чёрный, в третей: 2 белых и 2 чёрных. Найти $P(A)$ --
вытащили белый мячик, 
гипотезы $H_i$ -- вытащили из i-й урны,
$P(H_1)=P(H_2)=P(H_3)$. $P(A/H_1) = \frac{2}{3}$,
$P(A/H_2)=\frac{3}{4}$, $P(A/H_3) = \frac{1}{2}$. Ну а далее применяем
формулу полных вероятностей.

** Формула Байесса. Теорема гипотез
Итак имеется полная группа гипотез $H_1,\ldots,H_n$. Известны $P(H_k)$
-- априорные вероятности гипотез. Имея возможность провести опыт $A$
мы можем скорректировать вероятности. Итак порой очень часто важно иметь
апостериорные вероятности
$P(H_k/A)=\frac{P(H_k)P(A/H_k)}{P(A)}$. Пример тот же с тремя урнами.

* Случайные величины
*Случайная величина* -- это величина, которая в результате опыта
приобретает определённое числовое значение, заранее неизвестное. Это
определение для домохозяек, а математическое это:

Пусть тройка $(\Omega, U, P)$ -- некоторое вероятностное
пространство, *случайной величиной* $\xi$ называют действительную
функцию $\xi=\xi(\omega)$, где $\omega \in \Omega$, такую, что при
\forall действительных X $\{\omega: \xi(\omega)<X\}\subset U$.

Область возможных значений случайной величины X может быть дискретной
либо непрерывной, соответственно их разделяют на 2 класса: а)
дискретные случайные величины и б) непрерывные случайные величины. Как
задать описание случайной величины? Наиболее полное описание случайной
величины -- это закон распределения случайной величины (всякое
соотношение, указывающее связь между возможными значениями случайной
величины и их вероятностями. 

*Дискретные случайные величины*. Для них применяется ряд вероятностей
 случайной величины

| X | X_1 | X_2 | \ldots | X_n |
|---+-----+-----+--------+-----|
| P | P_1 | P_2 | \ldots | P_n |

При этом $\sum P_n = 1$

Ещё можно задавать многоугольником.

Функция распределения. $F(x) = P(X < x)$, $x \in (-\infty,+\infty)$
Свойства:
1. $F(x)$ -- неубывающая
2. $\lim_{x\to-\infty}F(x)=0$, т.к. $P(\varnothing)=0$
3. $\lim_{x\to+\infty}F(x)=1$, т.к. $P(\Omega)=1$
4. $P(a < x \leqslant b) = F(b) - F(a)$

Для дискретной случайной
величины. $F(x)=P(X<x)=\sum_{x_k<x}P(X=x_k)$. При всём этом $F(x)$ --
ступенчатая. Зная функцию распределения можно построить ряд
распределения.

Теперь об особенностях $F(x)$ для непрерывной случайной
величины. $F(x)$ -- непрерывна, монотонна.

Плотность распределения непрерывной случайной величины. Пусть $x$ --
непрерывная случайная величина. $P(X=x) \equiv 0$, поэтому таблица
невозможна. $P(x \leqslant X < x + \delta x)$. Нормируем это счастье
$\frac{P(x\leqslant X < x + \delta x)}{\delta x} = \frac{F(x+\delta
x) - F(x)}{\delta x}$. Тогда в предельном переходе
$f(x)=\frac{dF(x)}{d(x)}$. Теперь восстановим функцию распределения:

$$
    F(x) = \int^x_{-\infty}f(\xi)d\xi
$$

Свойства:
1. $f(x)\geqslant 0$
2. $\int^{+\infty}_{-\infty}f(x) dx = 1$
3. $P(a<x<b)=\int^b_a f(x) dx$

Резюме. Для дискретных случайных величин: ряд распределения и функция
распределения. Для непрерывных случайных величин: функция
распределения и плотность распределения.

Дополнение. Иногда возникает соблазн использовать и там и там
плотность распределения. Распространим плотность на дискретные
случайные величины, для этого используются так называемая $\delta(x)$

\begin{equation}
\delta(x) = \left\{\begin{aligned}
            &\infty, &x=0, \\
            & 0,     &x \neq 0
            \end{aligned}\right.
\end{equation}

На неё наложено следующее ограничение:
$\int^{+\infty}{-\infty}\delta(x)dx = 1$.

Дельта функция обладает важным фильтрующим свойством.
$g(y)=\int^{+\infty}{-\infty} g(x) \delta (y - x) dx$ --
свёртка. Используется для выделения значения функции $g$.

Пусть X -- дискретная случайная величина, заданная таблицей
вероятностей. Вводим функцию плотности 
$$
f(x) = \sum^n_{k=1} P_k \delta(x - x_k)
$$

* Числовые характеристики случайной величины
Это неполное знание о случайной величине, но оно может быть
достаточным для каких-то целей 
1. Мода случайной величины -- наибольшее возможное значение случайной
   величины. Если много пиков у плотностей распределения, то говорят,
   что закон распределения полимодальный (много мод)
2. Квантиль распределения порядка $p$ -- $x_p$. Он определяется из
   условия $F(x_p) = P(X < x_p) = p$. Их ввели, когда надо было
   работать с плотностями распределений, заданных на
   бесконечности. Квантили малых и больших порядков применяются для
   ограничения области возможных значений случайных величин. Например
   самые малые $x_{0.001},x_{0.999}$, самые частые
   $x_{0.05},x_{0.95}$. Основное назначение квантилей -- задать
   область интересующих нас значений.
3. Медиана. $\mu_e = x_{0.5}$, задаёт среднюю точку распределения.

* Характеристики, основанные на моментах распределения случайной величины
Математическое ожидание $M[X] = \sum_{i=1}^{n} x_i R_i =
\int_{-\infty}^{\infty} x f(x) dx$
Пусть мы провели серию из $N$ опытов $x^{(1)}, x^{(2)}, \ldots, x^{(n)}$.
Построим среднее арифметическое $\hat {\bar x} = \frac{1}{N} \sum_{i=1}^{N}
x^{(i)}$ (случайная величина). Если $M$ возрастает, то $x$
стабилизируется у некоторого числового значения. В предельном переходе
$\lim_{N \to \infty} \frac{1}{N} \sum x_i = M[X]$ (закон больших
чисел, вторая формулировка). 
# добавить крышечку к $\hat\bar x$
Пусть $X$ -- случайная величина и $\varphi (X)$ некоторая функция от
$X$.
$M\left[\varphi \left(X\right) \right] = \sum_{i=1}^{n} \varphi (x_i)
p_i = \int_{-\infty}^{\infty} \varphi (x) f(x) dx$
Начальные моменты:
$m_k = M[X^k] = \sum_{i=1}^{n} x_{i}^{k} p_i = \int_{-\infty}^{\infty}
x^k f(x) dx$ - (начальные моменты к-ого порядка), $k = 0, 1, 2, 3, \ldots$
$\mu_k = M\[(x-\bar x)^k\]=\sum (x_i - \bar x)p_i = \int (x-\bar
x)f(x) dx$ -- центральные моменты, $k = 0,1,2,\ldots$
$m_k$ и $\mu_k$ связаны:
1. $\mu_1 = 0$
2. $\mu_2 = m_2 - m_1^2$
3. $\mu_3 = m_3 - 3m_1m_2 + 2m_1^3$

Можно показать, что зная все моменты $m_k, \mu_k$, $k=0,\ldots$ можно
точно восстановить закон распределения. 

** Числовые характеристики, основанные на первых четырёх моментах.
1. Мат.ожидание случайной величины (среднее случайной величины): $$\bar
   x = M[x]=m_1=\sum x_ip_i = \int\limits^{+\infty}_{-\infty} xf(x)dx$$. Эта характеристика
   "положения" закона распределения, указывает около какого значения
   разыгрываются значения случайной величины. 
2. Дисперсия: $$ D_x = \varsigma^2_x = \mu_2 = M[(x-\bar x)^2]$$
   Также введём среднеквадратичное отклонение: $$ \varsigma_x =
   \sqrt{D_x} $$
3. Коэффициент вариации (волны на море -- представим волны на море,
   развился какой-то волновой процесс (в разрезе, продольные волны),
   разброс:
    $$ \r_x=\frac{\varsigma_x}{\bar x} $$
4. Коэффициент асимметрии. Пример:
   \begin{gather*}
   \bar x_1 = \bar x_2 = \bar x_3 \\
   \varsigma_1^2 = \varsigma_2^2 = \varsigma_3^2
# и тут няшная картинка
   \end{gather*}
   $$ \gamma = \frac{\mu_3}{\varsigma^3} = \frac{M[(x-\bar
   x)^3]}{\varsigma^3}$$
   1. $\gamma = 0$ кубы чототам компенсируют, симметричные законы.
   2. $\gamma > 0$ для несимметричных законов, скошенных вправо.
   3. $\gamma < 0$ для несимметричных законов, скошенных влево.
 
5. Коэффициент эксцесса (характеристика
   плосковершинности/островершинности законов распределения)
   $$ \kappa = \frac{\mu_4}{\sigma^4} - 3 $$

* Некоторые важные законы распределения
** Равномерное распределение
Пусть $X$ --- непрерывная случайная величина, заданная на отрезке
$[\alpha, \beta]$, все значения равновозможны.
$$f(x) = \frac{1}{\beta-\alpha}, x \in [\alpha, \beta]$$
$$f(x) = 0, x \not \in [\alpha, \beta]$$
$$F(x) = 0, x < \alpha$$
$$F(x) = \frac{x-\alpha}{\beta-\alpha}, x \in [\alpha, \beta]$$
$$F(x) = 1, x > \beta$$
** ?
1. Моды нет
2. Медиана
   $$\mu_l = \frac{\alpha+\beta}{2}$$
3. Математическое ожидание
   $$\bar x = \frac{\alpha+\beta}{2}$$
4. Дисперсия
   $$D = \frac{(\beta - \alpha)^2}{12}$$
5. Среднеквадратичное отклонение
   $$\varsigma = \frac{\beta - \alpha}{2\sqrt{3}}$$
6. ??
   $$\gamma = 0$$
7. ??
   $$\kappa = -1.2$$
